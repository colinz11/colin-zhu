{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census Dataset\n",
    "\n",
    "Now, let's use a dataset with even more attributes, now with some of them being categorical (i.e. not numerical. e.g. \"married\" vs \"divorced\" vs \"single\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical library in python, gives us nice things like special kinds of arrays,\n",
    "# useful math functions, random numbers, etc.\n",
    "import numpy as np\n",
    "\n",
    "# Pandas library gives us Series data and DataFrames, which are two really useful ways\n",
    "# of representing data. Using pandas, we can easily filter, sort, or extract data.\n",
    "# Very easy to convert this data into native numpy or native Python objects.\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib is a standard library used in Data Science,\n",
    "# especially pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn includes everything we need to take our data and run Supervised Learning\n",
    "# or Unsupervised Learning algorithms on it.\n",
    "import sklearn\n",
    "\n",
    "# Import our Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Import our Neural Network Classifier (Multi-Layer Perceptron Classifier)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Import our KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import our Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import our Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import our Support Vector Machine Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# We'll use this at the end for evaluating our models\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use this new cleaned up dataset.\n",
    "dataset = \"datasets/full_census.csv\"\n",
    "\n",
    "# We can read in a properly formatted CSV using this helper function.\n",
    "# This reads it in as a pandas dataframe object, which gives us a lot\n",
    "# of the same functionality we get in Excel like filtering, sorting, etc\n",
    "df = pd.read_csv(dataset)\n",
    "\n",
    "# This head() function gives us the first 5 items, which Jupyter notebook\n",
    "# formats nicely for us.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can also use the describe function on a dataframe to get info on the categorical variables\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task\n",
    "\n",
    "Build a classifier using this dataset and all of the attributes to make a classifier to determine if male or female. Use [this link](http://fastml.com/converting-categorical-data-into-numbers-with-pandas-and-scikit-learn/) to determine how to convert categorical fields into numerical fields for use with Neural Networks, Naive Bayes, and all the other supervised learning algorithms. It will be called __DictVectorizer.__\n",
    "\n",
    "- Create test/train splits (again, 70% and 30%, respectively)\n",
    "- Try at least 3 different parameters for your classifiers, plot your test/train errors\n",
    "- Try at least 2 different ML algorithms: Neural Network (MLPClassifier), Naive Bayes, KNN, DecisionTree, DecisionForest\n",
    "\n",
    "- Explain why your best performing model had such high test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#census_dict = df[ cols_to_retain ].to_dict( orient = 'records' )\n",
    "#vectorizer = DictVectorizer( sparse = False )\n",
    "#df = vectorizer.fit_transform( census_dict )\n",
    "cols = []\n",
    "y_value = \" race\"\n",
    "\n",
    "cols = [' workclass', ' education', ' education-num', ' marital-status', ' occupation', \n",
    "        ' relationship', ' sex', ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country', \n",
    "        ' wealth_class'  ]\n",
    "\n",
    "df = pd.get_dummies(data=df, columns=cols)\n",
    "\n",
    "# This is how many examples we have.\n",
    "n_samples = df.shape[0]\n",
    "print(n_samples)\n",
    "\n",
    "# TODO: Compute train_size and test_size\n",
    "train_size = int(n_samples * 0.70)\n",
    "test_size = n_samples - train_size\n",
    "\n",
    "print(\"Training set size: {}\".format(train_size))\n",
    "print(\"Test set size: {}\".format(test_size))\n",
    "\n",
    "\n",
    "df_X = df.drop(y_value, axis=1)\n",
    "df_y = df[y_value]\n",
    "\n",
    "# We need to now create our test and train splits\n",
    "\n",
    "# We'll train on 70% of our data\n",
    "train_X = df_X[:train_size]\n",
    "train_y = df_y[:train_size]\n",
    "# The remaining samples are for our test set\n",
    "\n",
    "test_X = df_X[train_size:]\n",
    "test_y = df_y[train_size:]\n",
    "\n",
    "\n",
    "epoch_counts = [5, 10, 100, 500, 1000, 2000] # We'll loop over this and set the MLP max iterations to this\n",
    "classifiers = [] # Append your classifiers here after applying .fit() to them\n",
    "\n",
    "train_accs = [] # Append train accuracies here\n",
    "test_accs = [] # Append test accuracies here\n",
    "results = []\n",
    "for epoch_count in epoch_counts:\n",
    "    # TODO: Use the epoch_count variable here, refer to MLP docs\n",
    "    classifier = MLPClassifier(max_iter=epoch_count)\n",
    "    # TODO: Use the fit() function here\n",
    "    classifiers.append(classifier.fit(train_X, train_y))\n",
    "    # TODO: Compute the accuracies below\n",
    "    train_error = classifier.score(train_X, train_y)\n",
    "    test_error = classifier.score(test_X, test_y)\n",
    "    \n",
    "    #results.append(classifier.predict(test_X))\n",
    "    train_acc = train_error\n",
    "    test_acc = test_error\n",
    "    print(\"Train:\", train_acc)\n",
    "    print(\"Test\", test_acc)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    # Now let's plot the results\n",
    "print(\"done\")    \n",
    "#plt.plot(epoch_counts, train_accs, \"g\")\n",
    "#plt.plot(epoch_counts, test_accs, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
