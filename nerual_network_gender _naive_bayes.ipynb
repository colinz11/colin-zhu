{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier By Hand\n",
    "\n",
    "We're going to create our own Naive Bayes classifier to classify if the given information about a person's height, weight, and age indicate that this person is male or female.\n",
    "\n",
    "For this, we'll use a custom dataset called `people.csv`, which you'll find in the `datasets/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This gives us dataframes which will allow us to build our custom\n",
    "# Naive Bayes Classifier\n",
    "import pandas as pd\n",
    "\n",
    "# Standard numeric library that gives us optimized arrays and vectors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import the Multi-Layer Perceptron Classifier. This is the model we will train.\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white_king_file</th>\n",
       "      <th>white_king_rank</th>\n",
       "      <th>white_rook_file</th>\n",
       "      <th>white_rook_rank</th>\n",
       "      <th>black_king_file</th>\n",
       "      <th>black_king_rank</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  white_king_file  white_king_rank white_rook_file  white_rook_rank  \\\n",
       "0               a                1               b                3   \n",
       "1               a                1               c                1   \n",
       "2               a                1               c                1   \n",
       "3               a                1               c                1   \n",
       "4               a                1               c                2   \n",
       "\n",
       "  black_king_file  black_king_rank result  \n",
       "0               c                2   draw  \n",
       "1               c                2   draw  \n",
       "2               d                1   draw  \n",
       "3               d                2   draw  \n",
       "4               c                1   draw  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"datasets/chess.csv\"\n",
    "\n",
    "# We can read in a properly formatted CSV using this helper function.\n",
    "# This reads it in as a pandas dataframe object, which gives us a lot\n",
    "# of the same functionality we get in Excel like filtering, sorting, etc\n",
    "df = pd.read_csv(dataset)\n",
    "\n",
    "# This head() function gives us the first 5 items, which Jupyter notebook\n",
    "# formats nicely for us.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training Set and Test Set\n",
    "\n",
    "Now, we're going to split our dataset up into test and training. We want 70% of our data to go for testing, 30% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28056\n",
      "Training set size: 19639\n",
      "Test set size: 8417\n"
     ]
    }
   ],
   "source": [
    "# This is how many examples we have.\n",
    "n_samples = df.shape[0]\n",
    "print(n_samples)\n",
    "\n",
    "# TODO: Compute train_size and test_size\n",
    "train_size = int(n_samples * 0.70)\n",
    "test_size = n_samples - train_size\n",
    "\n",
    "print(\"Training set size: {}\".format(train_size))\n",
    "print(\"Test set size: {}\".format(test_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cde05fe6d5d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# TODO: Use the fit() function here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m# TODO: Compute the accuracies below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtrain_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[0;32m--> 185\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;31m# boost the variance by epsilon, a small fraction of the standard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# deviation of the largest dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-9\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_refit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m-> 3157\u001b[0;31m                          **kwargs)\n\u001b[0m\u001b[1;32m   3158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Note that if dtype is not of inexact type then arraymean will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# not be either.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0marrmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         arrmean = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "gender = []\n",
    "for row in df.itertuples():\n",
    "    row = list(row)\n",
    "    gender.append(row[4])\n",
    "    del row[4]\n",
    "    del row[0]\n",
    "    row = tuple(row)\n",
    "    data.append(row)\n",
    "    \n",
    "# We need to now create our test and train splits\n",
    "\n",
    "# We'll train on 70% of our data\n",
    "train_X = data[:train_size]\n",
    "train_y = gender[:train_size]\n",
    "# The remaining samples are for our test set\n",
    "\n",
    "test_X = data[train_size:]\n",
    "test_y = gender[train_size:]\n",
    "\n",
    "\n",
    "epoch_counts = [5, 10, 20, 50, 100, 140, 200, 500, 1000, 2000] # We'll loop over this and set the MLP max iterations to this\n",
    "classifiers = [] # Append your classifiers here after applying .fit() to them\n",
    "\n",
    "train_accs = [] # Append train accuracies here\n",
    "test_accs = [] # Append test accuracies here\n",
    "\n",
    "for epoch_count in epoch_counts:\n",
    "    # TODO: Use the epoch_count variable here, refer to MLP docs\n",
    "    classifier = GaussianNB()\n",
    "    # TODO: Use the fit() function here\n",
    "    classifier.fit(train_X, train_y)\n",
    "    # TODO: Compute the accuracies below\n",
    "    train_error = classifier.score(train_X, train_y)\n",
    "    test_error = classifier.score(test_X, test_y)\n",
    "    train_acc = train_error\n",
    "    test_acc = test_error\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    # Now let's plot the results\n",
    "plt.plot(epoch_counts, train_accs, \"g\")\n",
    "plt.plot(epoch_counts, test_accs, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Recap: Bayes Theorem\n",
    "\n",
    "Bayes theorem is a famous equation that allows us to make predictions based on data:\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Specifically, we're trying to figure out the class (i.e. \"male\" or \"female\") of an observation _given_ the data\n",
    "\n",
    "$$\n",
    "p(class \\mid \\mathbf{data}) = \\frac{p(\\mathbf{data} \\mid class) * p(class)}{p(\\mathbf{data})}\n",
    "$$\n",
    "\n",
    "\n",
    "where:\n",
    "- class is a particular class (i.e. \"male\" or \"female\")\n",
    "- $\\mathbf{data}$ is an observation's data (the features)\n",
    "- $p(class \\mid \\mathbf{data})$ is called the posterior\n",
    "- $p(\\mathbf{data} \\mid class)$ is called the likelihood\n",
    "- $p(class)$ is called the prior\n",
    "- $p(\\mathbf{data})$ is called the marginal probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Theorem Applied to Predicting \"Male\" or \"Female\"\n",
    "\n",
    "$$\n",
    "p(person\\:is\\:male \\mid \\mathbf{person's\\:data}) = \\frac{\n",
    "p(\\mathbf{person's\\:data}\\mid person\\:is\\:male) * p(person\\:is\\:male)\n",
    "}{\n",
    "p(\\mathbf{person's\\:data})\n",
    "}\n",
    "$$\n",
    "\n",
    "#### More Specifically:\n",
    "Let's factor in height, weight, age\n",
    "$$\n",
    "posterior(male) = \\frac{\n",
    "p(height \\mid male)\\,p(weight|male)\\,p(age \\mid male)\\,p(male)\n",
    "}{\n",
    "\\mathit{marginal\\;probability}\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "__Two things to note:__\n",
    "\n",
    "1. We assume each feature is uncorrelated from each other. This independence assumption of Naive Bayes is what makes it \"Naive\". This assumption may not be true in the real world but let's stick with it and see what happens.\n",
    "\n",
    "2. We assume that the value of the features (height of the women, weight of the women) are normally (gaussian) distributed. This means that $p(height \\mid female)$ is calculated by inputing the required parameters into the probability density function of the normal distribution:\n",
    "\n",
    "__WARNING__: Very mathy, but we'll just have one helper function do this for us.\n",
    "\n",
    "$$\n",
    "p(height \\mid female) = \\frac{1}{\\sqrt{2\\pi(\\text{variance of female height in data})}}\n",
    "- e^{-\\frac{\n",
    " (\\text{observation's height} - \\text{average height of females in the data})^2\n",
    "}{\n",
    "2*(\\text{variance of female height in data})\n",
    "}\n",
    "}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Documentation\n",
    "Refer to [pandas docs](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.var.html) for this next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Bayes Classifier to New Data Point\n",
    "\n",
    "Now, all we have to do when we get a new datapoint is extract the features out and compare which label has a higher\n",
    "probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
